{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第十七章"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.1 示例：网络下载的三种风格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=A9e9Cy1UkME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1.1依序下载的脚本 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CN  IN  US  ID  BR  PK  NG  BD  RU  JP  MX  PH  VN  ET  EG  DE  IR  TR  CD  FR  \n",
      "20 flags downloaded in 8.42s\n"
     ]
    }
   ],
   "source": [
    "#flags.py\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import requests  # <1>\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()  # <2>\n",
    "\n",
    "BASE_URL = 'http://flupy.org/data/flags'  # <3>\n",
    "\n",
    "DEST_DIR = 'downloads/'  # <4>\n",
    "\n",
    "\n",
    "def download_many(cc_list):\n",
    "    for cc in cc_list:\n",
    "        img=get_flag(cc)\n",
    "        show(cc)\n",
    "        save_flag(img,cc.lower()+'.gif')\n",
    "    return len(cc_list)\n",
    "\n",
    "def get_flag(cc):\n",
    "    url='{}/{cc}/{cc}.gif'.format(BASE_URL,cc=cc.lower())\n",
    "    resp=requests.get(url)\n",
    "    return resp.content\n",
    "\n",
    "def show(cc):\n",
    "    print(cc,end='  ')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def save_flag(img,filename):\n",
    "    path=os.path.join(DEST_DIR,filename)\n",
    "    with open(path,'wb') as fp:\n",
    "        fp.write(img)\n",
    "\n",
    "def main(download_many):\n",
    "    t0=time.time()\n",
    "    count=download_many(POP20_CC)\n",
    "    elapsed=time.time()-t0\n",
    "    msg='\\n{} flags downloaded in {:.2f}s'\n",
    "    print(msg.format(count,elapsed))\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    main(download_many)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1.2 使用concurrent.futures模块下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD  DE  BRID  EG    CN  FR  RU  NG  TR  VN  IN  JP  ET  PH  CD  MX  US  IR  PK  \n",
      "20 flags downloaded in 0.63s\n"
     ]
    }
   ],
   "source": [
    "#flags_threadpool.py\n",
    "from concurrent import futures\n",
    "MAX_workers = 20\n",
    "def download_one(cc):\n",
    "    image=get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image,cc.lower()+'.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    workers=min(MAX_workers,len(cc_list))#设置工作的线程数量\n",
    "    with futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res=executor.map(download_one,sorted(cc_list))#download_one函数会在多个线程中并发调用；map方法返回一个生成器\n",
    "    return len(list(res))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1.3 期物在哪里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled for BR:<Future at 0x1c3353eb0b8 state=running>\n",
      "Scheduled for CN:<Future at 0x1c3353645f8 state=running>\n",
      "Scheduled for ID:<Future at 0x1c3353fa940 state=running>\n",
      "Scheduled for IN:<Future at 0x1c3353fa860 state=pending>\n",
      "Scheduled for US:<Future at 0x1c3353fa128 state=pending>\n",
      "BR  <Future at 0x1c3353eb0b8 state=finished returned str> result:'BR'\n",
      "ID  <Future at 0x1c3353fa940 state=finished returned str> result:'ID'\n",
      "CN  <Future at 0x1c3353645f8 state=finished returned str> result:'CN'\n",
      "IN  <Future at 0x1c3353fa860 state=finished returned str> result:'IN'\n",
      "US  <Future at 0x1c3353fa128 state=finished returned str> result:'US'\n",
      "\n",
      "5 flags downloaded in 0.95s\n"
     ]
    }
   ],
   "source": [
    "#flags_threadpool_ac.py\n",
    "from concurrent import futures\n",
    "MAX_workers = 20\n",
    "def download_one(cc):\n",
    "    image=get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image,cc.lower()+'.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    cc_list=cc_list[:5]\n",
    "    with  futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        to_do=[]\n",
    "        for cc in sorted(cc_list):\n",
    "            future=executor.submit(download_one,cc)#排定可调用对象的执行时间，然后返回一个期物，表示这个待执行的操作\n",
    "            to_do.append(future)#存储各个期物，后面传给as_completed函数\n",
    "            msg='Scheduled for {}:{}'\n",
    "            print(msg.format(cc,future))\n",
    "        \n",
    "        results=[]\n",
    "        for future in futures.as_completed(to_do):#as_completed函数在期物运行结束后产出期物\n",
    "            res=future.result()\n",
    "            msg='{} result:{!r}'\n",
    "            print(msg.format(future,res))\n",
    "            results.append(res)\n",
    "    return len(results)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "严格来说，我们目前测试的并发脚本都不能并行下载。使用concurrent.futures库实现的那两个示例受GIL（Global Interpreter Lock,全局解释锁）的限制。\n",
    "故有此疑问：既然python线程受GIL限制，任何时候都只允许运行一个线程，那么flags_threadpool.py脚本下载速度为什么会比flags.py脚本块5倍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.2 阻塞型I/O和GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chapter17-2](images/chapter17-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.3 使用concurrent.futures模块启动进程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concurrent.futures模块可以使用ProcessPoolExecutor类把工作分配给多个python进程处理。因此，如果需要CPU密集型处理，使用这个模块能绕开GIL，利用所有可用的cpu核心。\n",
    "下载国旗的示例或其他I/O密集型作业使用ProcessPoolExecutor类得不到任何好处。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "def download_one(cc):\n",
    "    image=get_flag(cc)\n",
    "    show(cc)\n",
    "    save_flag(image,cc.lower()+'.gif')\n",
    "    return cc\n",
    "\n",
    "def download_many(cc_list):\n",
    "    #ProcessPoolExecutor类不需设置max_workers参数，默认使用电脑cpu的数量\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        res=executor.map(download_one,sorted(cc_list))#download_one函数会在多个线程中并发调用；map方法返回一个生成器\n",
    "    return len(list(res))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chapter17-3](images/chapter17-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，ProcessPoolExecutor类在I/O密集型作业中不占优。它的价值主要体现在cpu密集型作业上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.4使用executor.map方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:48:45] Script starting.\n",
      "[10:48:45] loiter(0):doing nothing for 0s...\n",
      "[10:48:45] \tloiter(1):doing nothing for 1s...\n",
      "[10:48:45] loiter(0): done.\n",
      "[10:48:45] \t\tloiter(2):doing nothing for 2s...\n",
      "[10:48:45][10:48:45]  \t\t\tloiter(3):doing nothing for 3s...\n",
      "results: <generator object Executor.map.<locals>.result_iterator at 0x000001C33584B2B0>\n",
      "[10:48:45] Waiting for individual results:\n",
      "[10:48:45] result 0: 0\n",
      "[10:48:46] \tloiter(1): done.\n",
      "[10:48:46] \t\t\t\tloiter(4):doing nothing for 4s...\n",
      "[10:48:46] result 1: 10\n",
      "[10:48:47] \t\tloiter(2): done.\n",
      "[10:48:47] result 2: 20\n",
      "[10:48:48] \t\t\tloiter(3): done.\n",
      "[10:48:48] result 3: 30\n",
      "[10:48:50] \t\t\t\tloiter(4): done.\n",
      "[10:48:50] result 4: 40\n"
     ]
    }
   ],
   "source": [
    "#demo_executor_map.py\n",
    "from time import sleep,strftime\n",
    "from concurrent import futures\n",
    "\n",
    "def display(*args):\n",
    "    print(strftime('[%H:%M:%S]'),end=' ')\n",
    "    print(*args)\n",
    "\n",
    "def loiter(n):\n",
    "    msg='{}loiter({}):doing nothing for {}s...'\n",
    "    display(msg.format('\\t'*n,n,n))\n",
    "    sleep(n)\n",
    "    msg = '{}loiter({}): done.'\n",
    "    display(msg.format('\\t'*n, n))\n",
    "    return n * 10\n",
    "\n",
    "def main():\n",
    "    display('Script starting.')\n",
    "    executor=futures.ThreadPoolExecutor(max_workers=3)#创建ThreadPoolExecutor实例，有三个线程\n",
    "    results=executor.map(loiter,range(5))#把五个任务交给executor(因为只有三个线程，所以有三个任务会立即开始：loiter(0)，loiter(1)，loiter(2))；这是非阻塞调用\n",
    "    display('results:',results)\n",
    "    display('Waiting for individual results:')\n",
    "    for i, result in enumerate(results):  \n",
    "        display('result {}: {}'.format(i, result))\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.5显示下载进度并处理错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5.1 flags2系列示例处理错误的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flags2_commom.py\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import string\n",
    "import argparse\n",
    "from collections import namedtuple\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "Result = namedtuple('Result', 'status data')\n",
    "\n",
    "HTTPStatus = Enum('Status', 'ok not_found error')\n",
    "\n",
    "POP20_CC = ('CN IN US ID BR PK NG BD RU JP '\n",
    "            'MX PH VN ET EG DE IR TR CD FR').split()\n",
    "\n",
    "DEFAULT_CONCUR_REQ = 1\n",
    "MAX_CONCUR_REQ = 1\n",
    "\n",
    "SERVERS = {\n",
    "    'REMOTE': 'http://flupy.org/data/flags',\n",
    "    'LOCAL':  'http://localhost:8001/flags',\n",
    "    'DELAY':  'http://localhost:8002/flags',\n",
    "    'ERROR':  'http://localhost:8003/flags',\n",
    "}\n",
    "DEFAULT_SERVER = 'REMOTE'\n",
    "\n",
    "DEST_DIR = 'downloads/'\n",
    "COUNTRY_CODES_FILE = 'country_codes.txt'\n",
    "\n",
    "\n",
    "def save_flag(img, filename):\n",
    "    path = os.path.join(DEST_DIR, filename)\n",
    "    with open(path, 'wb') as fp:\n",
    "        fp.write(img)\n",
    "\n",
    "\n",
    "def initial_report(cc_list, actual_req, server_label):\n",
    "    if len(cc_list) <= 10:\n",
    "        cc_msg = ', '.join(cc_list)\n",
    "    else:\n",
    "        cc_msg = 'from {} to {}'.format(cc_list[0], cc_list[-1])\n",
    "    print('{} site: {}'.format(server_label, SERVERS[server_label]))\n",
    "    msg = 'Searching for {} flag{}: {}'\n",
    "    plural = 's' if len(cc_list) != 1 else ''\n",
    "    print(msg.format(len(cc_list), plural, cc_msg))\n",
    "    plural = 's' if actual_req != 1 else ''\n",
    "    msg = '{} concurrent connection{} will be used.'\n",
    "    print(msg.format(actual_req, plural))\n",
    "\n",
    "\n",
    "def final_report(cc_list, counter, start_time):\n",
    "    elapsed = time.time() - start_time\n",
    "    print('-' * 20)\n",
    "    msg = '{} flag{} downloaded.'\n",
    "    plural = 's' if counter[HTTPStatus.ok] != 1 else ''\n",
    "    print(msg.format(counter[HTTPStatus.ok], plural))\n",
    "    if counter[HTTPStatus.not_found]:\n",
    "        print(counter[HTTPStatus.not_found], 'not found.')\n",
    "    if counter[HTTPStatus.error]:\n",
    "        plural = 's' if counter[HTTPStatus.error] != 1 else ''\n",
    "        print('{} error{}.'.format(counter[HTTPStatus.error], plural))\n",
    "    print('Elapsed time: {:.2f}s'.format(elapsed))\n",
    "\n",
    "\n",
    "def expand_cc_args(every_cc, all_cc, cc_args, limit):\n",
    "    codes = set()\n",
    "    A_Z = string.ascii_uppercase\n",
    "    if every_cc:\n",
    "        codes.update(a+b for a in A_Z for b in A_Z)\n",
    "    elif all_cc:\n",
    "        with open(COUNTRY_CODES_FILE) as fp:\n",
    "            text = fp.read()\n",
    "        codes.update(text.split())\n",
    "    else:\n",
    "        for cc in (c.upper() for c in cc_args):\n",
    "            if len(cc) == 1 and cc in A_Z:\n",
    "                codes.update(cc+c for c in A_Z)\n",
    "            elif len(cc) == 2 and all(c in A_Z for c in cc):\n",
    "                codes.add(cc)\n",
    "            else:\n",
    "                msg = 'each CC argument must be A to Z or AA to ZZ.'\n",
    "                raise ValueError('*** Usage error: '+msg)\n",
    "    return sorted(codes)[:limit]\n",
    "\n",
    "\n",
    "def process_args(default_concur_req):\n",
    "    server_options = ', '.join(sorted(SERVERS))\n",
    "    parser = argparse.ArgumentParser(\n",
    "                description='Download flags for country codes. '\n",
    "                'Default: top 20 countries by population.')\n",
    "    parser.add_argument('cc', metavar='CC', nargs='*',\n",
    "                help='country code or 1st letter (eg. B for BA...BZ)')\n",
    "    parser.add_argument('-a', '--all', action='store_true',\n",
    "                help='get all available flags (AD to ZW)')\n",
    "    parser.add_argument('-e', '--every', action='store_true',\n",
    "                help='get flags for every possible code (AA...ZZ)')\n",
    "    parser.add_argument('-l', '--limit', metavar='N', type=int,\n",
    "                help='limit to N first codes', default=sys.maxsize)\n",
    "    parser.add_argument('-m', '--max_req', metavar='CONCURRENT', type=int,\n",
    "                default=default_concur_req,\n",
    "                help='maximum concurrent requests (default={})'\n",
    "                      .format(default_concur_req))\n",
    "    parser.add_argument('-s', '--server', metavar='LABEL',\n",
    "                default=DEFAULT_SERVER,\n",
    "                help='Server to hit; one of {} (default={})'\n",
    "                      .format(server_options, DEFAULT_SERVER))\n",
    "    parser.add_argument('-v', '--verbose', action='store_true',\n",
    "                help='output detailed progress info')\n",
    "    args = parser.parse_args()\n",
    "    if args.max_req < 1:\n",
    "        print('*** Usage error: --max_req CONCURRENT must be >= 1')\n",
    "        parser.print_usage()\n",
    "        sys.exit(1)\n",
    "    if args.limit < 1:\n",
    "        print('*** Usage error: --limit N must be >= 1')\n",
    "        parser.print_usage()\n",
    "        sys.exit(1)\n",
    "    args.server = args.server.upper()\n",
    "    if args.server not in SERVERS:\n",
    "        print('*** Usage error: --server LABEL must be one of',\n",
    "              server_options)\n",
    "        parser.print_usage()\n",
    "        sys.exit(1)\n",
    "    try:\n",
    "        cc_list = expand_cc_args(args.every, args.all, args.cc, args.limit)\n",
    "    except ValueError as exc:\n",
    "        print(exc.args[0])\n",
    "        parser.print_usage()\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not cc_list:\n",
    "        cc_list = sorted(POP20_CC)\n",
    "    return args, cc_list\n",
    "\n",
    "\n",
    "def main(download_many, default_concur_req, max_concur_req):\n",
    "    args, cc_list = process_args(default_concur_req)\n",
    "    actual_req = min(args.max_req, max_concur_req, len(cc_list))\n",
    "    initial_report(cc_list, actual_req, args.server)\n",
    "    base_url = SERVERS[args.server]\n",
    "    t0 = time.time()\n",
    "    counter = download_many(cc_list, base_url, args.verbose, actual_req)\n",
    "    assert sum(counter.values()) == len(cc_list), \\\n",
    "        'some downloads are unaccounted for'\n",
    "    final_report(cc_list, counter, t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flags2_sequential.py:负责下载的基本函数\n",
    "import requests\n",
    "import collections\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def get_flag(base_url,cc):\n",
    "    url='{}/{cc}/{cc}.gif'.format(base_url,cc=cc.lower())\n",
    "    resp=requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        resp.raise_for_status()\n",
    "    return resp.content\n",
    "\n",
    "def download_one(cc,base_url,verbose=False):\n",
    "    try:\n",
    "        img=get_flag(base_url,cc)\n",
    "    except requests.exceptions.HTTPError as exc:\n",
    "        res=exc.response\n",
    "        if res.status_code ==404:\n",
    "            status=HTTPStatus.not_found\n",
    "            msg='not found'\n",
    "        else:\n",
    "            raise\n",
    "    else:\n",
    "        save_flag(img,cc.lower()+'.gif')\n",
    "        status=HTTPStatus.ok\n",
    "        msg='ok'\n",
    "    if verbose:\n",
    "        print(cc,msg)\n",
    "    return Result(status,cc)\n",
    "\n",
    "def download_many(cc_list,base_url,verbose,max_req):\n",
    "    counter = collections.Counter()\n",
    "    cc_iter = sorted(cc_list)\n",
    "    if not verbose:\n",
    "        cc_iter=tqdm.tqdm(cc_iter)\n",
    "    for cc in cc_iter:\n",
    "        try:\n",
    "            res=download_one(cc,base_url,verbose)\n",
    "        except requests.exceptions.HTTPError as exc:\n",
    "            error_msg = 'HTTP error {res.status_code}-{res.reason}'\n",
    "            error_msg = error_msg.format(res=exc.response)\n",
    "        except requests.exceptions.ConnectionError as exc:\n",
    "            error_msg = 'Connection Error'\n",
    "        else:\n",
    "            error_msg = ''\n",
    "            status = res.status\n",
    "        if error_msg:\n",
    "            status = HTTPStatus.error\n",
    "        counter[status]+=1\n",
    "        if verbose and error_msg:\n",
    "            print('*** Errir for {}:{}'.format(cc,error_msg))\n",
    "    return counter\n",
    "if __name__ == '__main__':\n",
    "    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5.2 使用futures.as_completed函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Download flags of countries (with error handling).\n",
    "\n",
    "ThreadPool version\n",
    "\n",
    "Sample run::\n",
    "\n",
    "    $ python3 flags2_threadpool.py -s ERROR -e\n",
    "    ERROR site: http://localhost:8003/flags\n",
    "    Searching for 676 flags: from AA to ZZ\n",
    "    30 concurrent connections will be used.\n",
    "    --------------------\n",
    "    150 flags downloaded.\n",
    "    361 not found.\n",
    "    165 errors.\n",
    "    Elapsed time: 7.46s\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# BEGIN FLAGS2_THREADPOOL\n",
    "import collections\n",
    "from concurrent import futures\n",
    "\n",
    "import requests\n",
    "import tqdm  # <1>\n",
    "\n",
    "from flags2_common import main, HTTPStatus  # <2>\n",
    "from flags2_sequential import download_one  # <3>\n",
    "\n",
    "DEFAULT_CONCUR_REQ = 30  # <4>\n",
    "MAX_CONCUR_REQ = 1000  # <5>\n",
    "\n",
    "\n",
    "def download_many(cc_list, base_url, verbose, concur_req):\n",
    "    counter = collections.Counter()\n",
    "    with futures.ThreadPoolExecutor(max_workers=concur_req) as executor:  # <6>\n",
    "        to_do_map = {}  # <7>\n",
    "        for cc in sorted(cc_list):  # <8>\n",
    "            future = executor.submit(download_one,\n",
    "                            cc, base_url, verbose)  # <9>\n",
    "            to_do_map[future] = cc  # <10>\n",
    "        done_iter = futures.as_completed(to_do_map)  # <11>\n",
    "        if not verbose:\n",
    "            done_iter = tqdm.tqdm(done_iter, total=len(cc_list))  # <12>\n",
    "        for future in done_iter:  # <13>\n",
    "            try:\n",
    "                res = future.result()  # <14>\n",
    "            except requests.exceptions.HTTPError as exc:  # <15>\n",
    "                error_msg = 'HTTP {res.status_code} - {res.reason}'\n",
    "                error_msg = error_msg.format(res=exc.response)\n",
    "            except requests.exceptions.ConnectionError as exc:\n",
    "                error_msg = 'Connection error'\n",
    "            else:\n",
    "                error_msg = ''\n",
    "                status = res.status\n",
    "\n",
    "            if error_msg:\n",
    "                status = HTTPStatus.error\n",
    "            counter[status] += 1\n",
    "            if verbose and error_msg:\n",
    "                cc = to_do_map[future]  # <16>\n",
    "                print('*** Error for {}: {}'.format(cc, error_msg))\n",
    "\n",
    "    return counter\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)\n",
    "# END FLAGS2_THREADPOOL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
